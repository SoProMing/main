{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create portable version\n",
    "\n",
    "<img src=\"Export_jupiter.webp\" style=\"width:280px; height:280px;\">\n",
    "\n",
    "This page describes and actually impliments, how to make the jupyter notebooks of the whole project portable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive HTML exporting and link replacement\n",
    "\n",
    "This one is in use right now to create linked and working html pages.\n",
    "\n",
    "To achieve this, you can write a Python script that:\n",
    "\n",
    "1. Recursively searches for `.ipynb` files in a directory.\n",
    "2. Exports each `.ipynb` file to an HTML file.\n",
    "3. Replaces links within the HTML files that point to `.ipynb` files with `.html` links (so that the links work correctly in a browser).\n",
    "\n",
    "You can use the following libraries:\n",
    "- `os` or `pathlib` for file traversal.\n",
    "- `nbconvert` for converting `.ipynb` to `.html`.\n",
    "- `re` for regular expressions to replace links in HTML content.\n",
    "\n",
    "## Prerequesits\n",
    "\n",
    "### Install the Required Modules\n",
    "\n",
    "You can install the necessary modules using the following commands in your terminal or command prompt.\n",
    "\n",
    "1.  **Install  `nbconvert`**: This module is used to convert Jupyter notebooks to HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  **Install  `nbformat`**: This module is used to read and write Jupyter notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.9 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbformat > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's an outline of the script:\n",
    "\n",
    "### Script: Convert and Modify Links in HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "import re\n",
    "\n",
    "def convert_ipynb_to_html(ipynb_file):\n",
    "    # Load the notebook\n",
    "    with open(ipynb_file, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Convert to HTML\n",
    "    html_exporter = HTMLExporter()\n",
    "    (body, resources) = html_exporter.from_notebook_node(notebook)\n",
    "    \n",
    "    # Define the HTML filename\n",
    "    html_filename = os.path.splitext(ipynb_file)[0] + '.html'\n",
    "\n",
    "    if os.path.isfile(html_filename):\n",
    "        os.remove(html_filename)\n",
    "    \n",
    "    # Write the HTML file in the same directory as the ipynb file\n",
    "    with open(html_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(body)\n",
    "    \n",
    "    return html_filename\n",
    "\n",
    "def replace_ipynb_links_in_html(html_file, root_dir):\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Replace .ipynb links with relative .html links\n",
    "    updated_content = re.sub(\n",
    "        r'(?<=href=[\"\\'])(.*?\\.ipynb)(#.*)?(?=[\"\\'])', \n",
    "        lambda match: make_relative_html_link(match.group(1), match.group(2), root_dir), \n",
    "        content\n",
    "    )\n",
    "    \n",
    "    # Remove <details> and </details> lines\n",
    "    if \"SoProMing\" in html_file:\n",
    "        updated_content = remove_details_tags(updated_content)\n",
    "    \n",
    "    # Write the updated content back to the file\n",
    "    with open(html_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(updated_content)\n",
    "\n",
    "def remove_details_tags(html_content):\n",
    "    \"\"\"Remove all lines containing <details> or </details> tags.\"\"\"\n",
    "    lines = html_content.splitlines()\n",
    "    filtered_lines = [line for line in lines if '<details>' not in line and '</details>' not in line]\n",
    "    return '\\n'.join(filtered_lines)\n",
    "\n",
    "def make_relative_html_link(ipynb_link, anchor, root_dir):\n",
    "    # Convert .ipynb link to corresponding .html link\n",
    "    html_link = os.path.splitext(ipynb_link)[0] + '.html'\n",
    "    \n",
    "    # Get the absolute path of the html link\n",
    "    absolute_html_path = os.path.abspath(html_link)\n",
    "    \n",
    "    # Remove the root directory (CWD) from the absolute path to make it relative\n",
    "    relative_html_path = os.path.relpath(absolute_html_path, start=root_dir)\n",
    "\n",
    "    if anchor:\n",
    "        relative_html_path += anchor\n",
    "    \n",
    "    return relative_html_path\n",
    "\n",
    "def recursive_convert_and_replace_links(root_dir):\n",
    "    # Recursively find .ipynb files\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                ipynb_path = os.path.join(subdir, file)\n",
    "                \n",
    "                # Convert to HTML and save it in the same directory\n",
    "                html_file = convert_ipynb_to_html(ipynb_path)\n",
    "                \n",
    "                # Replace .ipynb links with relative .html links, removing the cwd from the path\n",
    "                replace_ipynb_links_in_html(html_file, root_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the current working directory as the root directory\n",
    "    root_directory = os.getcwd()\n",
    "    \n",
    "    recursive_convert_and_replace_links(root_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### How the Script Works:\n",
    "\n",
    "1. **Convert `.ipynb` to `.html`**: \n",
    "   - The `convert_ipynb_to_html` function uses `nbconvert` to convert a Jupyter Notebook (`.ipynb`) to an HTML file and saves it in the `output_dir`.\n",
    "\n",
    "2. **Replace `.ipynb` Links with `.html` Links**:\n",
    "   - The `replace_ipynb_links_in_html` function reads the generated HTML file, finds any links to `.ipynb` files, and replaces them with `.html` links.\n",
    "   - This is done using a regular expression that matches the links in the HTML content.\n",
    "\n",
    "3. **Recursively Process Files**:\n",
    "   - The `recursive_convert_and_replace_links` function walks through the directory tree (`os.walk`) and processes all `.ipynb` files. It calls the conversion and replacement functions for each file found.\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **File Paths**: Make sure to update the `root_directory` and `output_directory` variables to match your desired input and output paths.\n",
    "- **Dependencies**: You may need to install `nbconvert` and `nbformat` via `pip install nbconvert nbformat`.\n",
    "  \n",
    "This script will help you convert all `.ipynb` files to HTML and ensure that the links between notebooks are correctly pointing to the corresponding `.html` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all notebooks to one\n",
    "\n",
    "Working script... Combines all following the Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined notebook saved to /Users/starkj/Documents/2hands/Soproming/Repo/main/notebooks/SoProMing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from nbformat.v4 import new_markdown_cell\n",
    "import re\n",
    "\n",
    "def load_notebook(path):\n",
    "    \"\"\"Load a Jupyter Notebook file.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return nbformat.read(f, as_version=4)\n",
    "\n",
    "def extract_links(notebook):\n",
    "    \"\"\"Extract links to other .ipynb files from Markdown cells.\"\"\"\n",
    "    links = []\n",
    "    link_pattern = re.compile(r'\\[.*?\\]\\((.*?)\\)')\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            matches = link_pattern.findall(cell.source)\n",
    "            for match in matches:\n",
    "                # Remove URL fragments and query parameters\n",
    "                link = match.split('#')[0].split('?')[0]\n",
    "                link = link.strip()\n",
    "                if link.endswith('.ipynb'):\n",
    "                    links.append(link)\n",
    "    return links\n",
    "\n",
    "def find_file(base_path, relative_path):\n",
    "    \"\"\"\n",
    "    Try to find a file in the given base path or its subdirectories.\n",
    "    Args:\n",
    "        base_path: The root directory to search from.\n",
    "        relative_path: The relative path extracted from a link.\n",
    "    Returns:\n",
    "        The resolved absolute path if the file exists, or None.\n",
    "    \"\"\"\n",
    "    potential_paths = [\n",
    "        os.path.join(base_path, relative_path),\n",
    "        os.path.join(os.getcwd(), relative_path)\n",
    "    ]\n",
    "\n",
    "    # Also check all subdirectories of base_path\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if os.path.basename(file) == os.path.basename(relative_path):\n",
    "                potential_paths.append(os.path.join(root, file))\n",
    "\n",
    "    for path in potential_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "def adjust_links(source, notebook_dir, combined_dir):\n",
    "    \"\"\"Adjust links in Markdown cells and <img> tags to point to the correct locations.\"\"\"\n",
    "    # Adjust Markdown links\n",
    "    def replace_markdown_link(match):\n",
    "        text = match.group(1)\n",
    "        link = match.group(2)\n",
    "        link_clean = link.split('#')[0].split('?')[0]\n",
    "        if link_clean.endswith('.ipynb'):\n",
    "            section_name = os.path.splitext(os.path.basename(link_clean))[0]\n",
    "            adjusted_link = f\"#{section_name.replace(' ', '-')}\"\n",
    "            adjusted_link = f\"#{section_name.replace(' ', '-')}\"\n",
    "            return f\"{text}({adjusted_link})\"\n",
    "        else:\n",
    "            adjusted_path = os.path.relpath(\n",
    "                os.path.join(notebook_dir, link_clean),\n",
    "                combined_dir\n",
    "            )\n",
    "            return f\"{text}({adjusted_path})\"\n",
    "\n",
    "    # Adjust <img> tags\n",
    "    def replace_img_tag(match):\n",
    "        src = match.group(1)\n",
    "        src_clean = src.split('#')[0].split('?')[0]\n",
    "        adjusted_path = os.path.relpath(\n",
    "            os.path.join(notebook_dir, src_clean),\n",
    "            combined_dir\n",
    "        )\n",
    "        return f'<img src=\"{adjusted_path}\"'\n",
    "\n",
    "    # Apply adjustments\n",
    "    markdown_pattern = re.compile(r'(\\[.*?\\])\\((.*?)\\)')\n",
    "    img_pattern = re.compile(r'<img\\s+src=[\"\\'](.*?)[\"\\']')\n",
    "\n",
    "    adjusted_source = markdown_pattern.sub(replace_markdown_link, source)\n",
    "    adjusted_source = img_pattern.sub(replace_img_tag, adjusted_source)\n",
    "    return adjusted_source\n",
    "\n",
    "def combine_notebooks(base_path, notebook_path, visited=None, combined=None, combined_dir=None):\n",
    "    \"\"\"\n",
    "    Combine notebooks into one, following links recursively.\n",
    "\n",
    "    Args:\n",
    "        base_path: The base directory containing all notebooks.\n",
    "        notebook_path: Path to the current notebook relative to base_path.\n",
    "        visited: Set of already visited notebooks to avoid duplication.\n",
    "        combined: Combined notebook object.\n",
    "        combined_dir: Directory where the combined notebook will be saved.\n",
    "    \"\"\"\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if combined is None:\n",
    "        combined = nbformat.v4.new_notebook()\n",
    "\n",
    "    if combined_dir is None:\n",
    "        combined_dir = base_path\n",
    "\n",
    "    resolved_path = find_file(base_path, notebook_path)\n",
    "    if resolved_path is None:\n",
    "        print(f\"Warning: File {notebook_path} not found. Skipping.\")\n",
    "        return combined\n",
    "\n",
    "    notebook_key = os.path.relpath(resolved_path, base_path)\n",
    "    if notebook_key in visited:\n",
    "        return combined  # Avoid processing the same notebook twice\n",
    "\n",
    "    visited.add(notebook_key)\n",
    "\n",
    "    # Load the notebook\n",
    "    notebook = load_notebook(resolved_path)\n",
    "    notebook_dir = os.path.dirname(resolved_path)\n",
    "\n",
    "    # Add a heading to separate notebooks in the combined file\n",
    "    section_name = os.path.splitext(os.path.basename(notebook_path))[0]\n",
    "    page_break = \"\"\"<style>\n",
    "@media print {\n",
    "/* Erzwingt einen Seitenumbruch vor diesem Abschnitt */\n",
    ".page-break-before {\n",
    "    page-break-before: always; /* Alternative: break-before: page; */\n",
    "}\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"page-break-before\">\n",
    "                                    \n",
    "\"\"\"\n",
    "\n",
    "    combined.cells.append(new_markdown_cell(f\"\\n{page_break}\\n\\n##### {section_name}\\n\\n---\\n</div>\\n\"))\n",
    "\n",
    "    # Add cells from the current notebook\n",
    "    for cell in notebook.cells:\n",
    "        cell_copy = nbformat.from_dict(cell)\n",
    "        if cell.cell_type == 'markdown':\n",
    "            # Adjust links in Markdown cells and <img> tags\n",
    "            cell_copy.source = adjust_links(cell_copy.source, notebook_dir, combined_dir)\n",
    "        combined.cells.append(cell_copy)\n",
    "\n",
    "    # Find and process links to other notebooks\n",
    "    links = extract_links(notebook)\n",
    "    for link in links:\n",
    "        combine_notebooks(base_path, link, visited, combined, combined_dir)\n",
    "\n",
    "    return combined\n",
    "\n",
    "def main():\n",
    "    # Use the script's current working directory as the base path\n",
    "    base_path = os.getcwd()  # Current working directory where the script is executed\n",
    "    initial_notebook = \"abstract/Contents.de.ipynb\"  # Replace with the initial notebook's path relative to base_path\n",
    "\n",
    "    combined_notebook = combine_notebooks(base_path, initial_notebook)\n",
    "\n",
    "    # Save the combined notebook\n",
    "    output_path = os.path.join(base_path, \"SoProMing.ipynb\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(combined_notebook, f)\n",
    "\n",
    "    print(f\"Combined notebook saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "# Create PDF with beautiful soup and pdfkit\n",
    "\n",
    "Does not work so well.\n",
    "\n",
    "### 1.  **Extract Headlines from HTML Files:**\n",
    "\n",
    "-   You'll need to parse the HTML files to extract the headline tags (`<h1>`,  `<h2>`, etc.) and use them to generate the table of contents.\n",
    "-   The  `BeautifulSoup`  library from  `bs4`  is perfect for parsing HTML.\n",
    "\n",
    "### 2.  **Create the Table of Contents:**\n",
    "\n",
    "-   Use the extracted headlines to create a TOC in HTML format, with links to the corresponding sections.\n",
    "\n",
    "### 3.  **Insert the TOC at the Beginning of the Combined HTML File:**\n",
    "\n",
    "-   Add the generated TOC to the beginning of your combined HTML file before converting it to PDF.\n",
    "\n",
    "### 4.  **Convert to PDF:**\n",
    "\n",
    "-   Once you have the HTML with the TOC, convert it to PDF as before.\n",
    "\n",
    "Here’s a Python script that implements these steps:\n",
    "\n",
    "#### **Step 1: Install Necessary Libraries**\n",
    "\n",
    "You’ll need to install the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (4.12.3)\n",
      "Collecting pdfkit\n",
      "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from beautifulsoup4) (2.5)\n",
      "Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pdfkit\n",
      "Successfully installed pdfkit-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 pdfkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Python Script to Generate TOC and Convert HTML to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF with Table of Contents has been generated as 'output_with_toc.pdf'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfkit\n",
    "\n",
    "# Function to extract headlines from HTML\n",
    "def extract_headlines(html_content, file_index):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    headlines = []\n",
    "    for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "        for header in soup.find_all(tag):\n",
    "            # Create an anchor link for each headline\n",
    "            anchor = f\"section_{file_index}_{len(headlines)}\"\n",
    "            header['id'] = anchor\n",
    "            headlines.append((header.text.strip(), tag, anchor))\n",
    "    return headlines, str(soup)\n",
    "\n",
    "# Function to gather all HTML files recursively\n",
    "def gather_html_files(directory):\n",
    "    html_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb.html'):\n",
    "                html_files.append(os.path.join(root, file))\n",
    "    return sorted(html_files)  # Sorting ensures the order is preserved\n",
    "\n",
    "# Specify the top-level folder containing the HTML files\n",
    "top_level_folder = 'csharp'\n",
    "output_html = 'combined_with_toc.html'\n",
    "\n",
    "# Gather all HTML files recursively\n",
    "html_files = gather_html_files(top_level_folder)\n",
    "\n",
    "toc_entries = []\n",
    "full_html_content = \"<html><head><title>Document with TOC</title></head><body>\"\n",
    "\n",
    "# Generate the TOC and combine HTML files\n",
    "for i, filepath in enumerate(html_files):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        content = infile.read()\n",
    "        headlines, updated_html = extract_headlines(content, i)\n",
    "        toc_entries.extend(headlines)\n",
    "        full_html_content += updated_html\n",
    "        full_html_content += '<div style=\"page-break-after: always;\"></div>'\n",
    "\n",
    "# Create the TOC HTML structure\n",
    "toc_html = '<h1>Table of Contents</h1><ul>'\n",
    "for text, tag, anchor in toc_entries:\n",
    "    toc_html += f'<li><a href=\"#{anchor}\">{text}</a></li>'\n",
    "toc_html += '</ul><div style=\"page-break-after: always;\"></div>'\n",
    "\n",
    "# Add the TOC to the beginning of the document\n",
    "full_html_content = toc_html + full_html_content + \"</body></html>\"\n",
    "\n",
    "# Write the combined HTML with TOC to a file\n",
    "with open(output_html, 'w', encoding='utf-8') as outfile:\n",
    "    outfile.write(full_html_content)\n",
    "\n",
    "# Convert the combined HTML file with TOC to PDF\n",
    "pdfkit.from_file(output_html, 'output_with_toc.pdf')\n",
    "\n",
    "print(\"PDF with Table of Contents has been generated as 'output_with_toc.pdf'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Requirements:**\n",
    "\n",
    "1.  **wkhtmltopdf:**  Make sure  `wkhtmltopdf`  is installed on your system for  `pdfkit`  to work. You can download it from  wkhtmltopdf.org.\n",
    "2.  **HTML Structure:**  Ensure that your HTML files are well-formed, with proper heading tags for the TOC to be generated accurately.\n",
    "\n",
    "This script will produce a PDF with a generated Table of Contents at the beginning, linking to all the headlines within your HTML files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
